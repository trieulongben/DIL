{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression Consine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAaB_PkoxCGM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "X,Y= load_boston(return_X_y=True)\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y)\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class bostonData(Dataset):\n",
        "    def __init__(self):\n",
        "        X,Y= load_boston(return_X_y=True)\n",
        "        X=self.normalize(X)\n",
        "        x_train,x_test,y_train,y_test=train_test_split(X,Y)\n",
        "        self.x,self.y = x_train,y_train\n",
        "    def normalize(self,x):\n",
        "      mean=x.mean(axis=0)\n",
        "      std=x.std(axis=0)\n",
        "      return (x-mean/std)\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anmTzzoFxPCe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5195467c-45f2-44fc-e285-1418de385f3e"
      },
      "source": [
        "\n",
        "class LinearRegression():\n",
        "  def __init__(self):\n",
        "    from torch import nn\n",
        "    self.model=nn.Sequential(nn.Linear(13, 1)).double()\n",
        "    self.w=self.model[0].weight.data.normal_(0, 0.01).type(torch.float64)\n",
        "    self.b=self.model[0].bias.data.fill_(0).type(torch.float64)\n",
        "    #Model\n",
        "\n",
        "    \n",
        "    \n",
        "  def train(self,batch,lr,num_epocs):\n",
        "    dataset=DataLoader(bostonData(), batch_size=batch, shuffle=True)\n",
        "    trainer=torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "    #SGD\n",
        "    for epoc in range(num_epocs):\n",
        "      for x,y in dataset:\n",
        "        loss=self.loss()(self.model(x),y)\n",
        "        trainer.zero_grad()\n",
        "      \n",
        "        loss.backward()\n",
        "        trainer.step()\n",
        "      train_loss=self.loss()(self.model(x),y)\n",
        "      print(f'epoch {epoc + 1}, loss {float(train_loss.mean()):f}')\n",
        "  def loss(self):\n",
        "    return nn.MSELoss()\n",
        "\n",
        "model=LinearRegression()\n",
        "model.train(batch=4,lr=0.0000001,num_epocs=5000)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 35.619905\n",
            "epoch 2, loss 91.275328\n",
            "epoch 3, loss 77.016663\n",
            "epoch 4, loss 211.978459\n",
            "epoch 5, loss 45.161069\n",
            "epoch 6, loss 15.892641\n",
            "epoch 7, loss 77.322767\n",
            "epoch 8, loss 78.054989\n",
            "epoch 9, loss 60.225738\n",
            "epoch 10, loss 13.909347\n",
            "epoch 11, loss 254.144214\n",
            "epoch 12, loss 112.329849\n",
            "epoch 13, loss 59.229023\n",
            "epoch 14, loss 50.059157\n",
            "epoch 15, loss 55.900854\n",
            "epoch 16, loss 79.304766\n",
            "epoch 17, loss 31.964427\n",
            "epoch 18, loss 33.926661\n",
            "epoch 19, loss 146.958031\n",
            "epoch 20, loss 346.437193\n",
            "epoch 21, loss 121.763656\n",
            "epoch 22, loss 244.881336\n",
            "epoch 23, loss 106.689592\n",
            "epoch 24, loss 40.354637\n",
            "epoch 25, loss 60.286124\n",
            "epoch 26, loss 374.907803\n",
            "epoch 27, loss 155.958010\n",
            "epoch 28, loss 156.748235\n",
            "epoch 29, loss 60.349275\n",
            "epoch 30, loss 61.099844\n",
            "epoch 31, loss 61.978789\n",
            "epoch 32, loss 151.663084\n",
            "epoch 33, loss 13.807665\n",
            "epoch 34, loss 228.295109\n",
            "epoch 35, loss 94.166051\n",
            "epoch 36, loss 232.609940\n",
            "epoch 37, loss 163.769924\n",
            "epoch 38, loss 35.713515\n",
            "epoch 39, loss 5.785501\n",
            "epoch 40, loss 327.658142\n",
            "epoch 41, loss 63.318282\n",
            "epoch 42, loss 14.155129\n",
            "epoch 43, loss 261.244165\n",
            "epoch 44, loss 2.880280\n",
            "epoch 45, loss 37.354008\n",
            "epoch 46, loss 165.106977\n",
            "epoch 47, loss 71.237393\n",
            "epoch 48, loss 29.757449\n",
            "epoch 49, loss 95.153220\n",
            "epoch 50, loss 41.187819\n",
            "epoch 51, loss 157.250002\n",
            "epoch 52, loss 52.002347\n",
            "epoch 53, loss 61.860151\n",
            "epoch 54, loss 54.092736\n",
            "epoch 55, loss 80.397843\n",
            "epoch 56, loss 127.655596\n",
            "epoch 57, loss 35.489920\n",
            "epoch 58, loss 193.435711\n",
            "epoch 59, loss 57.044781\n",
            "epoch 60, loss 295.364500\n",
            "epoch 61, loss 31.411223\n",
            "epoch 62, loss 60.153973\n",
            "epoch 63, loss 141.328739\n",
            "epoch 64, loss 336.580475\n",
            "epoch 65, loss 46.927747\n",
            "epoch 66, loss 49.803132\n",
            "epoch 67, loss 60.711615\n",
            "epoch 68, loss 17.565050\n",
            "epoch 69, loss 409.340530\n",
            "epoch 70, loss 41.981830\n",
            "epoch 71, loss 43.794981\n",
            "epoch 72, loss 40.614037\n",
            "epoch 73, loss 186.686048\n",
            "epoch 74, loss 235.086593\n",
            "epoch 75, loss 59.097307\n",
            "epoch 76, loss 63.677166\n",
            "epoch 77, loss 30.302653\n",
            "epoch 78, loss 5.318995\n",
            "epoch 79, loss 220.567728\n",
            "epoch 80, loss 13.685767\n",
            "epoch 81, loss 19.806647\n",
            "epoch 82, loss 58.156787\n",
            "epoch 83, loss 34.178486\n",
            "epoch 84, loss 73.460953\n",
            "epoch 85, loss 94.125909\n",
            "epoch 86, loss 5.377740\n",
            "epoch 87, loss 43.555514\n",
            "epoch 88, loss 54.773197\n",
            "epoch 89, loss 3.733003\n",
            "epoch 90, loss 236.229520\n",
            "epoch 91, loss 328.775771\n",
            "epoch 92, loss 259.504055\n",
            "epoch 93, loss 52.341787\n",
            "epoch 94, loss 66.178824\n",
            "epoch 95, loss 19.764246\n",
            "epoch 96, loss 28.961827\n",
            "epoch 97, loss 127.386066\n",
            "epoch 98, loss 74.428617\n",
            "epoch 99, loss 10.550934\n",
            "epoch 100, loss 85.613380\n",
            "epoch 101, loss 38.282051\n",
            "epoch 102, loss 296.240344\n",
            "epoch 103, loss 17.728140\n",
            "epoch 104, loss 47.012298\n",
            "epoch 105, loss 12.306609\n",
            "epoch 106, loss 24.554448\n",
            "epoch 107, loss 87.482430\n",
            "epoch 108, loss 80.149370\n",
            "epoch 109, loss 54.284261\n",
            "epoch 110, loss 94.479867\n",
            "epoch 111, loss 107.494458\n",
            "epoch 112, loss 49.855815\n",
            "epoch 113, loss 203.686448\n",
            "epoch 114, loss 133.300088\n",
            "epoch 115, loss 121.209303\n",
            "epoch 116, loss 227.486138\n",
            "epoch 117, loss 296.621080\n",
            "epoch 118, loss 173.173948\n",
            "epoch 119, loss 28.533613\n",
            "epoch 120, loss 43.056978\n",
            "epoch 121, loss 218.318654\n",
            "epoch 122, loss 9.834937\n",
            "epoch 123, loss 64.342904\n",
            "epoch 124, loss 30.266447\n",
            "epoch 125, loss 221.347780\n",
            "epoch 126, loss 257.647785\n",
            "epoch 127, loss 74.938823\n",
            "epoch 128, loss 215.644641\n",
            "epoch 129, loss 319.854536\n",
            "epoch 130, loss 75.368270\n",
            "epoch 131, loss 189.355891\n",
            "epoch 132, loss 156.180501\n",
            "epoch 133, loss 23.997626\n",
            "epoch 134, loss 59.718822\n",
            "epoch 135, loss 105.390762\n",
            "epoch 136, loss 97.393744\n",
            "epoch 137, loss 85.501864\n",
            "epoch 138, loss 128.328452\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-17578d2f21fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-17578d2f21fe>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch, lr, num_epocs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKRLrMsuKpVR",
        "outputId": "83c6a939-395a-439c-a45e-b1b9effe5331"
      },
      "source": [
        "model.w"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0347,  0.0637, -0.0547, -0.0005, -0.1208, -0.0253,  0.0678,  0.0907,\n",
              "         -0.1238,  0.0155,  0.1709,  0.0292, -0.0483]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}